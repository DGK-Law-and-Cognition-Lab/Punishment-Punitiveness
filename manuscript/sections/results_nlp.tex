\subsection{Natural Language Processing Results}

The NLP analyses pursue two questions. First, is there a gap between the prosocial language people use to justify punishment and the semantic content of what they write? Second, if such a gap exists, what explains it---individual deception, genuine sincerity, or something else?

\subsubsection{The Prosocial Surface}

Across the 496 open-ended justifications, participants overwhelmingly invoked prosocial themes. When zero-shot classification assigned each response to its single most probable category, deterrence and prevention dominated (50.6\%), followed by proportional justice (11.9\%), public safety (9.1\%), and societal condemnation (7.5\%). Punishment and suffering was the top category in only 7.9\% of responses, and revenge and payback in 4.6\%. Multi-label classification told a similar story: the mean endorsement probability was highest for deterrence ($M = .85$), followed by proportional justice ($M = .80$), societal condemnation ($M = .73$), and public safety ($M = .65$). Collapsing across prosocial and dark categories, 87.5\% of responses were classified as primarily prosocial by zero-shot top-label assignment, 80.0\% by forced-choice classification, and 83.1\% by dictionary-based coding.

At face value, these results suggest that people justify punishment in prosocial terms. But a closer examination reveals a more complicated picture.

\subsubsection{The Semantic Mismatch}

Although participants framed their justifications in prosocial language, the \textit{semantic content} of those justifications was more closely aligned with dark themes than with prosocial ones. Using Sentence-BERT embeddings, we computed each response's cosine similarity to prototypical prosocial statements (deterrence, rehabilitation, incapacitation, retribution) and prototypical dark statements (revenge, suffering, exclusion). Despite the prosocial framing, 67.5\% of responses were semantically \textit{closer} to the dark prototypes than to the prosocial ones ($M_{\text{prosocial}} = .39$, $M_{\text{dark}} = .42$, paired $t(495) = 9.63$, $p < .001$, $d = 0.43$).

This finding was robust across multiple specifications. Using formal academic prototype sentences, 73.0\% of responses were closer to dark prototypes; using colloquial everyday prototypes, 89.7\% were. To address the concern that retribution could be classified as dark rather than prosocial, we tested two alternative specifications: removing retribution from the prosocial set (yielding a balanced 3 vs.\ 3 comparison) and moving retribution to the dark set. In both cases the finding strengthened---78.6\% and 83.5\% of responses were closer to dark prototypes, respectively---because retribution had been helping the prosocial side. The four NLP methods converged on the central pattern: prosocial categories dominated surface-level classifications (80--88\%), but the deeper semantic content tilted toward dark themes.\footnote{The two BART-based methods showed strong agreement (90.5\%, $\kappa = .66$). Agreement between BART and the dictionary or semantic similarity methods was more modest ($\kappa = .03$--.11), as expected given their different operating principles. Details are reported in the Supplementary Materials.}

\subsubsection{Three Competing Explanations}

What explains the mismatch between prosocial framing and dark semantic content? We tested three hypotheses, each making a distinct prediction about how the prosocial--dark gap should relate to individual differences.

\textit{Individual facade.} High-hostile individuals strategically adopt prosocial language to mask their darker motivations. This predicts that the prosocial--dark gap should correlate \textit{negatively} with hostile aggression: the more hostile the person, the more their prosocial framing should diverge from their dark content.

\textit{Sincerity.} Prosocial language reflects genuine crime concerns; the mismatch occurs because even crime-concerned individuals happen to produce language that resembles dark prototypes. This predicts that the prosocial--dark gap should correlate \textit{positively} with crime concerns.

\textit{Cultural default.} Everyone draws on the same culturally available prosocial script regardless of their psychological profile. The mismatch is a collective phenomenon, not an individual one. This predicts that the gap should be uncorrelated with \textit{both} hostile aggression and crime concerns.

The data decisively favored the cultural default. As shown in Table~\ref{tab:nlp_facade} and Figure~\ref{fig:facade_scatter}, hostile aggression was uncorrelated with prosocial language similarity ($r = -.04$, $p = .35$), dark language similarity ($r = -.01$, $p = .83$), the prosocial--dark gap ($r = -.03$, $p = .45$), and sentiment ($r = -.05$, $p = .25$). Two One-Sided Tests (TOST) equivalence testing with bounds of $\pm .15$ confirmed that four of five facade-relevant correlations were formally equivalent to zero (all $p_{\text{TOST}} \leq .014$); the one exception was dictionary-coded prosocial content ($r = -.08$, $p_{\text{TOST}} = .055$). Crime concerns were equally uninformative: the correlation between crime concerns and the prosocial--dark gap was $r = .06$ ($p = .20$). The facade and sincerity hypotheses were both unsupported.

Group comparisons reinforced this conclusion. Participants in the top and bottom tertiles of hostile aggression produced virtually identical language profiles (prosocial similarity: $M_{\text{low}} = .39$ vs.\ $M_{\text{high}} = .39$; dark similarity: $M_{\text{low}} = .42$ vs.\ $M_{\text{high}} = .42$; all $p$s $> .10$, all $d$s $< .16$). These null results were robust to the retribution classification: hostile aggression remained uncorrelated with both prosocial similarity and the prosocial--dark gap under all three prototype specifications (all $p$s $> .37$). Parallel analyses using dictionary prosocial scores, zero-shot category probabilities, and Empath categories yielded the same pattern, with the exception of a marginal trend for dictionary-coded prosocial content ($r = -.08$, $p = .08$).

The prosocial--dark gap was also uncorrelated with hatred ($r = .04$, $p = .41$), SDO ($r = -.06$, $p = .20$), RWA ($r = .04$, $p = .38$), and racial resentment ($r = -.06$, $p = .17$). Only revenge ($r = -.09$, $p = .04$) and punitiveness itself ($r = -.17$, $p < .001$) showed even marginal relationships. The cultural default interpretation treats the prosocial framing as a shared rhetorical resource---a folk theory of punishment that people absorb from legal discourse and media, rather than a deliberate strategy of concealment.

\subsubsection{The Cultural Default Across the Political Spectrum}

If the prosocial framing is a cultural default, it should operate similarly for liberals and conservatives despite their divergent levels of punitiveness. As shown in Table~\ref{tab:political_moderation}, conservatives were substantially more punitive ($M = 0.26$) and more hostile ($M = 4.12$) than liberals ($M = -0.31$ and $M = 3.33$, respectively). Yet their language was virtually identical: prosocial similarity was $.38$ for conservatives and $.39$ for liberals; dark similarity was $.41$ and $.43$; and the percentage of responses closer to dark prototypes was 64.7\% for conservatives and 67.9\% for liberals.

Formal interaction tests confirmed these patterns. The interaction between hostile aggression and political orientation (continuous) predicting prosocial similarity was nonsignificant ($b = -.002$, $p = .26$), as were interactions predicting the prosocial--dark gap ($b = -.002$, $p = .24$) and sentiment ($b = .004$, $p = .70$). Everyone used prosocial language to justify punishment regardless of their psychological profiles, and political orientation did not moderate this pattern.

\subsubsection{Text Features as Independent Predictors}

Although text features were unrelated to hostile aggression, they were related to punitiveness itself. More punitive individuals used less prosocial language ($r = -.13$, $p = .005$), had a more negative prosocial--dark gap ($r = -.17$, $p < .001$), and expressed more negative sentiment ($r = -.19$, $p < .001$). These correlations, while modest, indicate that punitiveness is weakly reflected in language---but this signal is far too weak to differentiate individuals by their hostile aggression.

To assess whether text features contribute unique variance beyond the quantitative measures, we conducted hierarchical regression (with vignette as a fixed-effects covariate). Regressing punitiveness on the four psychological clusters yielded $R^2 = .387$. Adding prosocial similarity, dark similarity, and sentiment increased this to $R^2 = .443$ ($\Delta R^2 = .055$, $F(3, 486) = 16.0$, $p < .001$). Prosocial similarity was the second-largest predictor ($\beta = -.23$, $p < .001$), behind only hostile aggression ($\beta = .32$, $p < .001$). Text features thus capture an aspect of punitiveness not fully explained by the psychological batteries---even though text features are themselves unrelated to hostile aggression.

Text features were even more informative for the sentencing decision itself. Rehabilitation language was the strongest predictor of shorter sentences ($r = -.45$, $p < .001$), followed by sentiment ($r = -.22$); revenge language predicted longer sentences ($r = .29$, $p < .001$). In hierarchical regression, psychological measures alone predicted sentencing at $R^2 = .117$; adding rehabilitation language and sentiment increased this to $R^2 = .258$ ($\Delta R^2 = .141$, $F(2, 488) = 46.5$, $p < .001$), and hostile aggression dropped to nonsignificance ($b = -0.01$, $p = .80$). The text features appear to capture the pathway through which dispositions translate into decisions: people who invoke rehabilitation give shorter sentences, and people who invoke revenge give longer ones, regardless of their hostile aggression scores.
